---
title: "STAT 331 Portfolio"
author: "Ella Leback"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
code-tools: true
code-fold: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an **A-**. I have tried to submit good work, but I have not been able to devote as much time to the content as I would have liked so I don't think I have done as much as I could have.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r}
#| label: wd-1-csv

surveys <- read_csv(here::here("data", "surveys.csv"))

#from lab 2 and challenge 2 Q #1
```

-   `xlsx`

```{r}
#| label: wd-1-xlsx

military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending", 
                      skip  = 7, 
                      n_max = 191)

read_xlsx(path = here::here("Week 2", "Checkins", "Ages_Data", "Ages_Data", "ages.xlsx"), sheet = "ages")

#P.A. 4 on military spending and Week 2 checkin in Q #1
```

-   `txt`

```{r}
#| label: wd-1-txt

read_delim(here::here("Week 2", "Checkins", "Ages_Data", "Ages_Data", 
                      "ages_mystery.txt"),
           delim = "|")

#Week 2 Checkin prompt #3
#Revised to include delimiter "|"
```

**WD-2: I can select necessary columns from a dataset.**

```{r}
#| label: wd-2

teacher_evals_clean <- evals |>
  rename(sex = gender) |>
  filter(no_participants > 10) |> 
  mutate(
    across(.cols = teacher_id:question_no,
           .fns = ~ as.factor(.x)) 
        ) |>
  select(course_id,
         teacher_id,
         question_no,
         no_participants,
         resp_share,
         SET_score_avg,
         percent_failed_cur,
         academic_degree,
         seniority,
         sex)

#From Lab 3 Q#5

```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r}
#| label: wd-3-numeric

teacher_evals_clean <- evals |>
  rename(sex = gender) |>
  filter(no_participants > 10) |> 
  mutate(
    across(.cols = teacher_id:question_no,
           .fns = ~ as.factor(.x)) 
        ) |>
  select(course_id,
         teacher_id,
         question_no,
         no_participants,
         resp_share,
         SET_score_avg,
         percent_failed_cur,
         academic_degree,
         seniority,
         sex)

#From Lab 3 Q#5
```

-   character -- specifically a string (example must use functions from **stringr**)

```{r}
#| label: wd-3-string
get_fit_now_check_in |>
  mutate(check_in_date = ymd(check_in_date)) |>
  right_join(get_fit_now_member, 
             by = join_by(membership_id == id)) |>
  inner_join(person,
             by = join_by(person_id == id,
                          name == name)) |>
  inner_join(drivers_license,
             by = join_by(license_id == id)) |>
  filter(check_in_date == "2018-01-09",
         membership_status == "gold",
         str_detect(membership_id, "^48Z"),
         str_detect(license_id, "[H42W]"))
#from lab 5, find suspect who visited Get Fit Now

facebook_event_checkin |>
  left_join(person,
             by = join_by(person_id == id)) |>
  filter(event_name == "SQL Symphony Concert",
         str_sub(date, 1, 4) == 2017,
         str_sub(date, 5, 6) == 12) |> ...

#initial code I used from lab 5 when finding who hired Jeremy Bowers using str_sub
```

-   factor

```{r}
#| label: wd-3-factor
ca_childcare_age <- ca_childcare |>
  pivot_longer(cols = mc_infant:mc_preschool,
               names_to = "Age",
               values_to = "price") |>
  mutate(Age = fct_recode(.f = Age,
                          "Infant" = "mc_infant",
                          "Toddler" = "mc_toddler",
                          "Preschool" = "mc_preschool"),
         Age = fct_relevel(Age, 
                           "Infant",
                           "Toddler",
                           "Preschool"),
         region = fct_recode(region, 
                             "Los Angeles County" = "Los Angeles",
                             "Orange County" = "Orange"),
         region = fct_relevel(region, 
                              "San Francisco Bay Area",
                              "Orange County",
                              "Los Angeles County",
                              "Northern San Joaquin Valley",
                              "Central Coast",
                              "Inland Empire",
                              "Superior California",
                              "Southern San Joaquin Valley",
                              "San Diego - Imperial",
                              "North Coast"))

ca_childcare_age |>
  filter(Age == levels(Age)[1]) |>
  ggplot(mapping = aes(x = mhi_2018,
                       y = price)) +
  geom_point() +
  geom_smooth(method = lm)

#Modified code from lab 4 Q #6 and #7 to create a new dataframe (to not overwrite ca_childcare) and filter the age by the infant factor level instead of just calling mc_infant

```

-   date (example must use functions from **lubridate**)

```{r}
#| label: wd-3-date

facebook_event_checkin |>
  left_join(person,
             by = join_by(person_id == id)) |>
  mutate(date = ymd(date)) |>
  filter(event_name == "SQL Symphony Concert",
         month(date) == 12,
         year(date) == 2017)

#use ymd to set date to a date type and use month and year functions to filter desired rows
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric (using `as.numeric()` is not sufficient)

```{r}
#| label: wd-4-numeric

ca_childcare |> 
  filter(study_year %in% c("2008", "2018")) |>
  group_by(region,
           study_year) |>
  mutate(median_mhi_2018 = median(mhi_2018, 
                                  na.rm = TRUE))

#from lab 4 q#4 to modify mhi_2018
```

-   character -- specifically a string (example must use functions from **stringr**)

```{r}
#| label: wd-4-string

ca_childcare <- ca_childcare |>
  mutate(county_name = str_remove(county_name, " County"),
         county_name = str_replace_all(county_name, "Orange", "Orange County"),
         county_name = str_replace_all(county_name, "Los Angeles", "Los Angeles County"))

#modified code from lab 4 Q#3 to rename Orange County and Los Angeles County to match official regions
```

-   factor (example must use functions from **forcats**)

```{r}
#| label: wd-4-factor

ca_childcare |>
  pivot_longer(cols = mc_infant:mc_preschool,
               names_to = "Age",
               values_to = "price") |>
  mutate(Age = fct_recode(.f = Age,
                          "Infant" = "mc_infant",
                          "Toddler" = "mc_toddler",
                          "Preschool" = "mc_preschool"),
         Age = fct_relevel(Age, 
                           "Infant",
                           "Toddler",
                           "Preschool"),
         region = fct_recode(region, 
                             "Los Angeles County" = "Los Angeles",
                             "Orange County" = "Orange"),
         region = fct_relevel(region, 
                              "San Francisco Bay Area",
                              "Orange County",
                              "Los Angeles County",
                              "Northern San Joaquin Valley",
                              "Central Coast",
                              "Inland Empire",
                              "Superior California",
                              "Southern San Joaquin Valley",
                              "San Diego - Imperial",
                              "North Coast"))

#from lab 4 Q#6

```

-   date (example must use functions from **lubridate**)

```{r}
#| label: wd-4-date

facebook_event_checkin |>
  left_join(person,
             by = join_by(person_id == id)) |>
  mutate(date = ymd(date)) |>
  filter(event_name == "SQL Symphony Concert",
         month(date) == 12,
         year(date) == 2017)

#use ymd to set date to a date type and use month and year functions to filter desired rows

```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r}
#| label: wd-5-left

facebook_event_checkin |>
  left_join(person,
             by = join_by(person_id == id)) |>
  mutate(date = ymd(date)) |>
  filter(event_name == "SQL Symphony Concert",
         month(date) == 12,
         year(date) == 2017)

#I modified code from lab 5 to figure out who attended the facebook event and get person info. I used a left join here so that each event would only have the corresponding people who attended and no extras
```

-   `right_join()`

```{r}
#| label: wd-5-right

get_fit_now_check_in |>
  mutate(check_in_date = ymd(check_in_date)) |>
  right_join(get_fit_now_member, 
             by = join_by(membership_id == id))

#from lab 5 to find get fit now suspects, and used right_join because fewer members so we could reduce missing values and instead see how many times each member checked in, when and see relevant membership info

```

-   `inner_join()`

```{r}
#| label: wd-5-inner

get_fit_now_check_in |>
  mutate(check_in_date = ymd(check_in_date)) |>
  right_join(get_fit_now_member, 
             by = join_by(membership_id == id)) |>
  inner_join(person,
             by = join_by(person_id == id,
                          name == name))

#from lab 5 to find get fit now suspects, and used inner_join here when adding person info because there were more entries in the person dataset, so this way we only keep those that match potential suspects
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r}
#| label: wd-6-semi

witness <- person |>
  filter(if_any(c(address_street_name), 
                ~ .x == "Northwestern Dr" & address_number == max(address_number)) |
           if_any(c(address_street_name, name), 
                  ~ .x == "Franklin Ave" & str_detect(name, "^Annabel")))

interview |>
  semi_join(witness,
            by = join_by(person_id == id))

#revised code from lab 5 and made witness dataframe to connect witness id to person_id to find interview statements

```

-   `anti_join()`

```{r}
#| label: wd-6-anti

mod_income <- income |>
  filter(annual_income <= 100000)

facebook_event_checkin |>
  left_join(person,
             by = join_by(person_id == id)) |>
  mutate(date = ymd(date)) |>
  filter(event_name == "SQL Symphony Concert",
         month(date) == 12,
         year(date) == 2017) |>
  left_join(drivers_license, 
               by = join_by(license_id == id)) |>
  anti_join(mod_income, 
             by = "ssn") |>
  filter(gender == "female",
         hair_color == "red",
         height %in% c("65", "66", "67"),
         car_make == "Tesla",
         car_model == "Model S")

#modified code from lab 5 when finding who hired Jeremy Bowers to use an anti_join of income to eliminate people who did make more than $100,000 a year
```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r}
#| label: wd-7-long

ca_childcare |>
  pivot_longer(cols = mc_infant:mc_preschool,
               names_to = "Age",
               values_to = "price")

#from lab 4 Q#6

```

-   `pivot_wider()`

```{r}
#| label: wd-7-wide

ca_childcare |> 
  filter(study_year %in% c("2008", "2018")) |>
  group_by(region,
           study_year) |>
  mutate(median_mhi_2018 = median(mhi_2018, 
                                  na.rm = TRUE)) |>
  select(region,
         study_year,
         median_mhi_2018) |>
  distinct() |>
  pivot_wider(names_from = study_year,
              values_from = median_mhi_2018) 

#from lab 4 Q#4

```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments: Lab 2, Lab 3

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

```{r}
#| label: r-2-1

ggplot(data = surveys,
       mapping = aes(x = species,
                     y = weight)) +
  geom_boxplot(outliers = FALSE) + #remove outliers
  geom_jitter(color = "steelblue",
              alpha = 0.5) +
  labs(subtitle = "Weight (g)",
       x = "Species",
       y = "") + #put y into subtitle so easier to read graph
   theme_bw() + # make plot more presentable
   theme(axis.text.x = element_text(angle = 45)) #rotate text 45 degrees


#from lab 2 Q#10 and revised to plot correctly and add comments

```

-   Example of **dplyr** pipeline

```{r}
#| label: r-2-2

teacher_evals_clean |>
  group_by(teacher_id,
           course_id) |> #organize data
  summarize(n = n_distinct(question_no)) |> #find number of distinct qs answered
  filter(n == 9) |> #keep only ids with all 9 question responses
  select(teacher_id,
         course_id) |> #keep teacher and course ids that match criteria
  distinct() #keep only one of each value

#revised code from lab 3 Q#9 to make code more tidy and added comments to make code well-documented

```

-   Example of function formatting

```{r}
#| label: r-2-3

rescale_01 <- function(vec) {
  
  stopifnot(is.numeric(vec),
            length(vec) > 1)
  
  range <- range(x, na.rm = TRUE)
  
  return((vec - range[1]) / (range[2] - range[1]))
}

#Revised code from lab 7 Q#5
```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example -- any context

```{r}
#| label: r-3-example

teacher_evals_clean |> 
  filter(seniority == 1) |>
  slice_max(order_by = percent_failed_cur) |>
  select(teacher_id, 
         percent_failed_cur) |>
  distinct()

# revised from lab 3 Q#11 to remove unnecessary grouping, use column names to resist changes

```

-   Example of function stops

```{r}
#| label: r-3-function-stops

rescale_01 <- function(vec) {
  
  stopifnot(is.numeric(vec),
            length(vec) > 1)
  
  range <- range(x, na.rm = TRUE)
  
  return((vec - range[1]) / (range[2] - range[1]))
}

#Revised code from lab 7 Q#5 to stop if criteria are not met
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   at least two numeric variables

```{r}
#| label: dvs-1-num

ggplot(data = surveys,
       mapping = aes(x = weight,
                     y = hindfoot_length
       )) +
  geom_point(alpha = 0.5) +
  facet_wrap(facets = vars(species)) +
  labs(title = "Effect of rodent weight on hind foot length by species",
       subtitle = "Hindfoot length (mm)",
       x = "Weight (g)",
       y = NULL)

#from Lab 2 Q#4

```

-   at least one numeric variable and one categorical variable

```{r}
#| label: dvs-2-num-cat

ggplot(data = surveys,
       mapping = aes(
         x = weight,
         y = species,
         color = genus)) +
  geom_boxplot(outliers = FALSE) + 
  geom_jitter(alpha = 0.2) +
  labs(subtitle = "Rodent Species",
       x = "Weight (g)",
       y = "") +
  annotate("text", y = 1, 
           x = 25, label = "Neotoma") +
  annotate("text", y = c(2, 12), 
           x = 250, label = "Chaetodipus") +
  annotate("text", y = c(3, 8), 
           x = 250, label = "Peromyscus") +
  annotate("text", y = 4, 
           x = 250, label = "Perognathus") +
  annotate("text", y = c(5, 9),
           x = 250, label = "Reithrodontomys") +
  annotate("text", y = 6, 
           x = 250, label = "Sigmodon") +
  annotate("text", y = c(7, 14), 
           x = 250, label = "Onychomys") +
  annotate("text", y = c(10, 11, 13), 
           x = 250, label = "Dipodomys") +
  theme(legend.position = "none") +
  theme_bw() +
  scale_color_brewer()

#Lab 2 challenge annotated boxplot with added theme_bw and 
#scale_color_brewer from my revised submission of challenge 2

```

-   at least two categorical variables

```{r}
#| label: dvs-1-cat

teacher_evals_compare |>
  ggplot(mapping = aes(
    x = sen_level)) +
  geom_bar(aes(fill = SET_level,)) +
  labs(x = "Seniority of Instructor",
       y = "",
       subtitle = "Number of Sections",
       fill = "SET Level") +
  scale_fill_manual(values = c("steelblue", "orange3")) +
  theme_bw() #added theme to match figure

#from revision of lab 3 challenge Q#2
```

-   dates (timeseries plot)

```{r}
#| label: dvs-1-date

ca_childcare |> #removed extra data manipulation that wasn't needed to show objective
  ggplot(mapping = aes(x = study_year,
                       y = price,
                       color = fct_reorder2(.f = region,
                                            .x = study_year,
                                            .y = price))) +
  geom_point()+
  facet_wrap(~ Age) +
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "") +
  geom_smooth() +
  scale_color_brewer(palette = "Paired", 
                     name = "California Region") +
  scale_x_continuous(breaks = c(2008, 2012, 2016)) +
  theme_bw() 

#revised from lab 4 Q#6

```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can ensure people don't tilt their head

```{r}
#| label: dvs-2-1

ggplot(data = surveys,
       mapping = aes(
         x = weight,
         y = species,
         color = genus)) +
  geom_boxplot(outliers = FALSE) + 
  geom_jitter(alpha = 0.2) +
  labs(subtitle = "Rodent Species",
       x = "Weight (g)",
       y = "") + #removed unneeded annotations
  theme(legend.position = "none") +
  theme_bw() +
  scale_color_brewer()

#Lab 2 challenge annotated boxplot with added theme_bw and scale_color_brewer from my revised submission 
```

-   I can modify the text in my plot to be more readable

```{r}
#| label: dvs-2-2

ca_childcare |> #removed extra data manipulation that wasn't needed to show objective
  ggplot(mapping = aes(x = study_year,
                       y = price,
                       color = fct_reorder2(.f = region,
                                            .x = study_year,
                                            .y = price))) +
  geom_point()+
  facet_wrap(~ Age) +
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "") +
  geom_smooth() +
  scale_color_brewer(palette = "Paired", 
                     name = "California Region") +
  scale_x_continuous(breaks = c(2008, 2012, 2016)) + #used breaks to remove text overlap
  theme_bw() +
  theme(legend.text = element_text(size = 8)) #shrink legend text to expand figures

#revised from lab 4 Q#6

```

-   I can reorder my legend to align with the colors in my plot

```{r}
#| label: dvs-2-3

ca_childcare |> #removed extra data manipulation that wasn't needed to show objective
  ggplot(mapping = aes(x = study_year,
                       y = price,
                       color = fct_reorder2(.f = region,
                                            .x = study_year,
                                            .y = price))) +
  geom_point()+
  facet_wrap(~ Age) +
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "") +
  geom_smooth() +
  scale_color_brewer(palette = "Paired", 
                     name = "California Region") +
  scale_x_continuous(breaks = c(2008, 2012, 2016)) +
  theme_bw() 

#revised from lab 4 Q#6

```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors

```{r}
#| label: dvs-3-1

ggplot(data = surveys,
       mapping = aes(
         x = weight,
         y = species,
         color = genus)) +
  geom_boxplot(outliers = FALSE) + 
  geom_jitter(alpha = 0.5) +
  labs(subtitle = "Rodent Species",
       x = "Weight (g)",
       y = "") +
  scale_color_brewer(palette = "BuPu") +
  theme_bw()

#Revision of lab 2 challenge spicy boxplot with added theme_bw and scale_color_brewer
```

-   I can use annotations

```{r}
#| label: dvs-3-2

#create a new dataframe to contain annotation info
annotations <- data.frame(
  label = c("Chaetodipus", "Chaetodipus", "Peromyscus", 
            "Peromyscus", "Perognathus", "Reithrodontomys", "Reithrodontomys", 
            "Sigmodon", "Onychomys", "Onychomys", "Dipodomys", "Dipodomys", 
            "Dipodomys"),
  y = c(2, 12, 3, 8, 4, 5, 9, 6, 7, 14, 10, 11, 13),
  x = 250
)

ggplot(data = surveys,
       mapping = aes(
         x = weight,
         y = species,
         color = genus)) +
  geom_boxplot(outliers = FALSE) + 
  geom_jitter(alpha = 0.2) +
  labs(subtitle = "Rodent Species Weight (g) with color by Genus",
       x = "Weight (g)",
       y = "") +
  annotate("text", y = 1, 
           x = 25, label = "Neotoma") +
  geom_text(data = annotations, 
        mapping = aes(x = x, y = y, label = label), 
        inherit.aes = FALSE) +
    theme_bw() +
  scale_color_brewer(palette = "PuBuGn") +
  theme(legend.position = "none")

#Revision of lab 2 Hot challenge of annotated boxplots with added theme_bw, scale_color_brewer, and a new dataframe to more efficiently enter a series of annotations

```

-   I can be creative...

```{r}
#| label: dvs-3-3

all_simulations |>
  mutate(n = as.factor(n),
         n = fct_recode(n,
                        "10 simulations" = "10",
                        "100 simulations" = "100",
                        "1000 simulations" = "1000",
                        "10000 simulations" = "10000")) |>
  ggplot(mapping = aes(x = simulated_means)) +
  geom_histogram(fill = "turquoise",
                 color = "black",
                 bins = 20) +
  facet_wrap(~n,
             scales = "free") +
  theme_bw() +
  labs(x = "Simulated Means",
       y = "",
       subtitle = "Count of Means",
       title = "Distribution of Simulated Means compared to the <span style='color:red;'>True Mean") +
  geom_vline(xintercept = 10,
             color = "red",
             show.legend = NA) +
  theme(plot.title = element_markdown())

#from lab 9 Q#8 and modified to label true means in the title red like in the plot
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

```{r}
#| label: dvs-4-summarize

teacher_evals_clean |>
  group_by(teacher_id,
           course_id) |>
  summarize(n = n_distinct(question_no)) |> #find number of distinct qs answered
  filter(n == 9) |> #keep only ids with all 9 question responses
  distinct() #keep only one of each value

#revised code from lab 3 Q#9 to make code more tidy

```

-   Example using `across()`

```{r}
#| label: dvs-4-across

fish |> 
  summarize(across(
    .cols = everything(),
    .fns = ~ sum(is.na(.x))
  ))
#from lab 7 Q#1 to find the number of missing values for each column in the dataset

```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r}
#| label: dvs-5-1

fish |> 
  group_by(species) |>
  summarize(across(
    .cols = everything(),
    .fns = ~ sum(is.na(.x))
  ))

#Modified code from lab 7 Q#1 to see the breakdown of missing values by species
```

-   Example 2

```{r}
#| label: dvs-5-2

teacher_evals_clean |>
  group_by(teacher_id,
           course_id) |>
  summarize(n = n_distinct(question_no)) |>
  filter(n == 9) |>
  select(teacher_id,
         course_id) |>
  distinct()

#revised from lab 3 Q#9

```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r}
#| label: dvs-6-1

results_df <- enframe(results, 
                      name = "simulation_number", 
                      value = "ncorrect") 

#head(results_df)
#saved as df for me to manipulate

results_df |>
  count(ncorrect, name = "sim_count") |>
  mutate(prop = (sim_count / sum(sim_count)
                 )
         ) |> #more adaptable to change of func inputs
  select(-sim_count) |>
  pivot_wider(names_from = "ncorrect",
              values_from = "prop"
              ) |>
  add_column(`3` = 0,
             .after = 3
             ) |> #used col position to place missing column
  #^ could use cols_move to move column
  rename("0 babies matched" = "0",
         "1 baby matched correctly" = "1",
         "2 babies matched correctly" = "2",
         "3 babies matched correctly" = "3",
         "All 4 babies matched correctly" = "4"
         ) |> #option to use gt func cols_label
  
  #challenge 9
  gt() |> 
  tab_header("Frequency of Correct Baby Matches") |> #add title
  fmt_percent() |> #set proportions to %
  #style header cells
  tab_style(style = list(cell_fill(color = "lightgray"),
                         cell_text(font = "arial")
                         ),
            locations = cells_column_labels()
            ) |>
  #style table cells
  tab_style(style = list(cell_fill(color = "lightcyan"),
                         cell_text(font = "arial")
                         ),
            locations = cells_body()
            ) |>
  #add borders
  tab_style(style = cell_borders(),
            locations = list(cells_body(),
                             cells_column_labels()
                             )
            )

#from lab 9 Q#2 for challenge 9

```

-   Example 2

```{r}
#| label: dvs-6-2

fish |>
  map_int(.x = fish,
          .f = ~ sum(is.na(.x), 
                     na.rm = FALSE)) |>
  as_tibble_row() |>
  rename("Trip" = "trip",
         "Mark" = "mark",
         "Length" = "length",
         "Weight" = "weight",
         "Year" = "year",
         "Section" = "section",
         "Species" = "species") |>
  kable() |>
  kable_styling(bootstrap_options = "striped")

#From lab 8 Q#4 for challenge 9
```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r}
#| label: dvs-7-1
results_df <- enframe(results, 
                      name = "simulation_number", 
                      value = "ncorrect") 

#head(results_df)
#saved as df for me to manipulate

results_df |>
  count(ncorrect, name = "sim_count") |>
  mutate(prop = (sim_count / sum(sim_count)
                 )
         ) |> #more adaptable to change of func inputs
  select(-sim_count) |>
  pivot_wider(names_from = "ncorrect",
              values_from = "prop"
              ) |>
  add_column(`3` = 0,
             .after = 3
             ) |> #used col position to place missing column
  #^ could use cols_move to move column
  rename("0 babies matched" = "0",
         "1 baby matched correctly" = "1",
         "2 babies matched correctly" = "2",
         "3 babies matched correctly" = "3",
         "All 4 babies matched correctly" = "4"
         ) |> #option to use gt func cols_label
  
  #challenge 9
  gt() |> 
  tab_header("Frequency of Correct Baby Matches") |> #add title
  fmt_percent() |> #set proportions to %
  #style header cells
  tab_style(style = list(cell_fill(color = "lightgray"),
                         cell_text(font = "arial")
                         ),
            locations = cells_column_labels()
            ) |>
  #style table cells
  tab_style(style = list(cell_fill(color = "lightcyan"),
                         cell_text(font = "arial")
                         ),
            locations = cells_body()
            ) |>
  #add borders
  tab_style(style = cell_borders(),
            locations = list(cells_body(),
                             cells_column_labels()
                             )
            )

#from lab 9 Q#2 using gt table
```

-   Example 2

```{r}
#| label: dvs-7-2

evals |>
  mutate(sen_level = if_else(as.numeric(seniority) <= 4,
                             "junior",
                             "senior")) |>
  select(sex, 
         sen_level, 
         academic_degree,
         teacher_id) |>
  distinct(teacher_id,
           .keep_all = TRUE) |>
  pivot_longer(cols = sex:academic_degree,
               names_to = "column",
               values_to = "values") |>
  count(values) |>
  pivot_wider(names_from = "values",
              values_from = "n") |>
  select(female,
         male, 
         junior, 
         senior, 
         no_dgr, 
         ma, 
         dr, 
         prof) |>
  rename("Female" = "female",
         "Male" = "male",
         "Junior (4 years or less)" = "junior",
         "Senior (more than 4 years)" = "senior",
         "No Degree" = "no_dgr",
         "Masters" = "ma",
         "Doctorate" = "dr",
         "Professor" = "prof") |>
  kable() |>
  kable_styling(bootstrap_options = "striped") |>
  add_header_above(c("Sex" = 2, 
                     "Seniority Level" = 2, 
                     "Academic Degree" = 4))

#modified from lab 8 Q#3 to add headers above selected variables to show more creativity using kableExtra
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

```{r}
#| label: pe-1-one-call

crime_scene_report <- crime_scene_report |>
  mutate(date = ymd(date)) |>
  filter(date == "2018-01-15",
         type == "murder",
         city == "SQL City") 

#from lab 5 to get preliminary crime info

```

-   `across()`

```{r}
#| label: pe-1-across

teacher_evals_clean <- evals |>
  rename(sex = gender) |>
  filter(no_participants > 10) |> 
  mutate(
      across(.cols = teacher_id:question_no,
             .fns = ~ as.factor(.x)) 
      )

#from lab 3 Q#5

```

-   `map()` functions

```{r}
#| label: pe-1-map-1

surveys |>
 map_chr(.x = surveys,
         .f = ~ class(.)) |>
 as_tibble_row() |>
 kable() |>
 kable_styling(bootstrap_options = "striped")

#from lab 8 Q#1 to find the variable type for each column

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Function that operates on vectors

```{r}
#| label: pe-2-1

evals <- evals |> 
  map_at(.at = c("teacher_id", 
                 "weekday", 
                 "academic_degree", 
                 "seniority", 
                 "sex"),
         .f = ~ as.factor(.)) |>
 kable() |>
 kable_styling(bootstrap_options = "striped")

#from lab 8 Q#2 to select columns within a vector
```

-   Function that operates on data frames

```{r}
#| label: pe-2-2

surveys |>
 map_chr(.x = surveys, #could remove .x for redundancy but is nice to have for clarity
         .f = ~ class(.)) |>
 as_tibble_row() |>
 kable() |>
 kable_styling(bootstrap_options = "striped")

#from lab 8 Q#1 to return variable type across all variables in the dataframe
```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

```{r}
#| label: pe-3-across

fish |> 
  summarize(across(
    .cols = everything(),
    .fns = ~ sum(is.na(.x))
  ))

#from lab 7 Q#1 to find missing values across all variables
```

-   `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

```{r}
#| label: pe-3-map-1

surveys |>
 map_chr(.x = surveys, #could remove .x for redundancy but is nice to have for clarity
         .f = ~ class(.)) |>
 as_tibble_row() |>
 kable() |>
 kable_styling(bootstrap_options = "striped")

#from lab 8 Q#1 to return variable type across all variables in the dataframe

fish |>
  map_int(.x = fish,
          .f = ~ sum(is.na(.x), 
                     na.rm = FALSE)) |>
#from lab 8 Q#4 to count NA values
```

-   `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

```{r}
#| label: pe-3-map-2

all_simulations <- grid |> 
  mutate(simulated_means = pmap(.l = list(n = n,
                                          df = df), 
                                .f = simulate_means)
         ) |> 
  unnest(simulated_means)

#from lab 9 Q#6
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

```{r}
#| label: pe-4-1

witness <- person |>
  filter(if_any(c(address_street_name), 
                ~ .x == "Northwestern Dr" & address_number == max(address_number)) |
           if_any(c(address_street_name, name), 
                  ~ .x == "Franklin Ave" & str_detect(name, "^Annabel")))

#revised code from lab 5 to identify the two witnesses based on the given information, used filter(if_any()) as my function

```

-   I can connect a data wrangling pipeline into a `ggplot()`

```{r}
#| label: pe-4-2

ca_childcare |>
  pivot_longer(cols = mc_infant:mc_preschool,
               names_to = "Age",
               values_to = "price") |>
  mutate(Age = fct_recode(.f = Age,
                          "Infant" = "mc_infant",
                          "Toddler" = "mc_toddler",
                          "Preschool" = "mc_preschool"),
         Age = fct_relevel(Age, 
                           "Infant",
                           "Toddler",
                           "Preschool"),
         region = fct_recode(region, 
                             "Los Angeles County" = "Los Angeles",
                             "Orange County" = "Orange")) |>
  ggplot(mapping = aes(x = study_year,
                       y = price,
                       color = fct_reorder2(.f = region,
                                            .x = study_year,
                                            .y = price)))

#from lab 4 Q#6

```

## Data Simulation & Statisical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r}
#| label: dsm-1-1

randomBabies <- function(nBabies){
  sim_babies <- tibble(babies = 1:4,
                       sim = sample(1:4,
                                    size = 4,
                                    replace = FALSE)) 
  
  correct_babies <- sim_babies |>
    mutate(is_match = babies == sim) |>
    summarize(total_matches = sum(is_match)) |>
    pull(total_matches)
  
  return(correct_babies)
}

results <- map_int(.x = 1:10000,
                   .f = ~randomBabies(nBabies = 4)
                   )

#from lab 9 Q#1 to simulate the distribution of the number of babies correctly returned to their parents using the sample function
```

-   Example 2

```{r}
#| label: dsm-1-2

simulate_means <- function(n, df){
  map_dbl(.x = 1:n, 
          .f = ~rchisq(n = 100, df = df) %>% mean()
          )
}

grid <- crossing(n = c(10, 100, 1000, 10000), 
                 df = 10)

all_simulations <- grid |> 
  mutate(simulated_means = pmap(.l = list(n = n,
                                          df = df), 
                                .f = simulate_means)
         ) |> 
  unnest(simulated_means)

#from lab 9 Q#4 to simulate the distribution of random chi square values
```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

```{r}
#| label: dsm-2-1

species_mod <- aov(data = surveys, weight ~ species)
summary(species_mod)

#from lab 2 Q#17

```

-   Example 2

```{r}
#| label: dsm-2-2

reg_mod1 <- lm(mc_infant ~ mhi_2018, data = ca_childcare)
summary(reg_mod1)

#from lab 4 Q#8

```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

I have revised work on most of my lab assignments to get a better understanding of how to code in a better way. For some of the code above, I needed to add more elements to make the graphs more visually appealing and professional. For some of my challenge 2 plots, I have revised them a few times as I learn new skills to make them even better then before. I also employed more efficient or new methods to make my code more modern or robust. This makes me a better coder, and it ingrains these ideas so that I will build on them as the quarter progresses. For labs 4 and 5, I was not able to submit revisions because I was at a conference that weekend which took up most of my time and prep leading up to it. However, I tried to still make revisions to several components of each lab and integrate that into my portfolio. For example, from lab 5 I revised some of my joins to be more efficient when it comes to limiting NAs and by using a variety of join types like semi and anti joins.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

I extended my thinking by applying what I learned in my challenge problems to code within the portfolio. Several of my data visualization code examples came from the lab 2 challenge problem which I revised to attempt some of the more complicated problems within the challenge. I have also gained a better understanding of what it takes to code tidily and efficiently and have used that in my personal research. I have also explored new methods of completing a task more efficiently such as using functions and across() for iteration. I have also revised and added to several aspects of my portfolio since the midterm review to provide even better examples that more closely align with the criteria and showcase my new skills as a coder.

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

In my lab 5 peer review, I tried to use a sandwich method for providing feedback to not be as harsh so that the person would be more likely to take my feedback and apply it in the future. I began by commenting that the code was pretty tidy by putting functions on new lines and using commas to end lines but there was some areas where named arguments weren't used or they could have added new lines in some other places. I also talked about how the code was efficient and some areas for improvement. They did a good job of using features like %in%, str_detect, or slice_max to more efficiently select relevant parts of the dataset. However, they used many intermediate objects, and had duplicate functions so I tried to encourage them to tidy their work space by creating fewer objects and to use a comma or pipe to make the code more efficient.

As a collaborator, I grew through the weekly activities by becoming more confident in sharing my ideas with my partner. Me and my partners got along pretty well, but we still try to follow the roles to get practice collaborating and to ensure that one of us doesn't overpower the conversation. It can be harder to follow the roles if we get stuck at a point, but we have gotten better about being comfortable asking for help and respecting the roles we each have. I think I have been a supportive partner even out of these activities because we communicate to help clarify lab questions.
